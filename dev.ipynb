{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from tox import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150.45795798301697\n",
      "(24085, 59099)\n",
      "{'scientific_article_unpublished': 8, 'email': 0, 'scientific_article_published': 9, 'boardroom_minutes': 2, 'advertisement': 10, 'annual_report': 3, 'internal_memo': 1, 'newspaper_article': 6, 'deposition': 7, 'public_relations': 4, 'trade_association': 11, 'general_correspondance': 5}\n"
     ]
    }
   ],
   "source": [
    "bson_file = 'documents.bson'\n",
    "label_key = 'document_type'\n",
    "text_key = 'text'\n",
    "\n",
    "# Process the raw data\n",
    "dp = DataProcessor()\n",
    "docs, y_all, counts = dp.load_bson(bson_file, label_key)\n",
    "t0 = time.time()\n",
    "vectorizer, X_all, feat_names = dp.vectorize(docs, text_key, min_df=2, max_ngram=2)\n",
    "vec_time = time.time() - t0\n",
    "\n",
    "y_train, X_train, y_test, X_test, y_unlab, X_unlab = dp.split_data(y_all, X_all, split=0.7, seed=0)\n",
    "me = ModelEvaluator()\n",
    "\n",
    "print(vec_time)\n",
    "print(X_all.shape)\n",
    "print(dp.label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.06094193458557129\n",
      "Accuracy: 0.686258935663\n",
      "email \n",
      " F1:  0.965, P:  0.940, R:  0.992, \n",
      "internal_memo \n",
      " F1:  0.000, P:  0.000, R:  0.000, \n",
      "boardroom_minutes \n",
      " F1:  0.000, P:  0.000, R:  0.000, \n",
      "annual_report \n",
      " F1:  0.000, P:  0.000, R:  0.000, \n",
      "public_relations \n",
      " F1:  0.000, P:  0.000, R:  0.000, \n",
      "general_correspondance \n",
      " F1:  0.056, P:  0.667, R:  0.029, \n",
      "newspaper_article \n",
      " F1:  0.596, P:  0.683, R:  0.528, \n",
      "deposition \n",
      " F1:  0.179, P:  0.909, R:  0.099, \n",
      "scientific_article_unpublished \n",
      " F1:  0.692, P:  0.564, R:  0.896, \n",
      "scientific_article_published \n",
      " F1:  0.020, P:  1.000, R:  0.010, \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shine/Documents/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/shine/Shared/toxic-docs/tox.py:184: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  dp.inv_label_dict[i], 2/(1/prec[i] + 1/rec[i]), prec[i], rec[i]))\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "MNB = MultinomialNB()\n",
    "MNB_train_acc, MNB_train_time = me.train(MNB, y_train, X_train)\n",
    "MNB_test_acc, MNB_test_prec, MNB_test_rec, MNB_test_time = me.test(MNB, y_test, X_test)\n",
    "print('Time: ', MNB_train_time)\n",
    "me.print_scores(dp, MNB_test_acc, MNB_test_prec, MNB_test_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.057497501373291016\n",
      "Accuracy: 0.676727561557\n",
      "email \n",
      " F1:  0.966, P:  0.959, R:  0.973, \n",
      "internal_memo \n",
      " F1:  0.000, P:  0.000, R:  0.000, \n",
      "boardroom_minutes \n",
      " F1:  0.000, P:  0.000, R:  0.000, \n",
      "annual_report \n",
      " F1:  0.000, P:  0.000, R:  0.000, \n",
      "public_relations \n",
      " F1:  0.000, P:  0.000, R:  0.000, \n",
      "general_correspondance \n",
      " F1:  0.000, P:  0.000, R:  0.000, \n",
      "newspaper_article \n",
      " F1:  0.574, P:  0.631, R:  0.527, \n",
      "deposition \n",
      " F1:  0.000, P:  0.000, R:  0.000, \n",
      "scientific_article_unpublished \n",
      " F1:  0.693, P:  0.563, R:  0.900, \n",
      "scientific_article_published \n",
      " F1:  0.000, P:  0.000, R:  0.000, \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shine/Documents/anaconda/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/shine/Shared/toxic-docs/tox.py:184: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  dp.inv_label_dict[i], 2/(1/prec[i] + 1/rec[i]), prec[i], rec[i]))\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes\n",
    "BNB = BernoulliNB()\n",
    "BNB_train_acc, BNB_train_time = me.train(BNB, y_train, X_train)\n",
    "BNB_test_acc, BNB_test_prec, BNB_test_rec, BNB_test_time = me.test(BNB, y_test, X_test)\n",
    "print('Time: ' + str(BNB_train_time))\n",
    "me.print_scores(dp, BNB_test_acc, BNB_test_prec, BNB_test_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.3663311004638672\n",
      "Accuracy: 0.769658459095\n",
      "email \n",
      " F1:  0.983, P:  0.980, R:  0.987, \n",
      "internal_memo \n",
      " F1:  0.577, P:  0.757, R:  0.467, \n",
      "boardroom_minutes \n",
      " F1:  0.679, P:  0.818, R:  0.581, \n",
      "annual_report \n",
      " F1:  0.533, P:  1.000, R:  0.364, \n",
      "public_relations \n",
      " F1:  0.286, P:  1.000, R:  0.167, \n",
      "general_correspondance \n",
      " F1:  0.455, P:  0.514, R:  0.409, \n",
      "newspaper_article \n",
      " F1:  0.696, P:  0.677, R:  0.715, \n",
      "deposition \n",
      " F1:  0.623, P:  0.940, R:  0.465, \n",
      "scientific_article_unpublished \n",
      " F1:  0.762, P:  0.708, R:  0.824, \n",
      "scientific_article_published \n",
      " F1:  0.471, P:  0.821, R:  0.330, \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC (liblinear SVM implementation, one-v-all)\n",
    "SVMlin = LinearSVC()\n",
    "SVMlin_train_acc, SVMlin_train_time = me.train(SVMlin, y_train, X_train)\n",
    "SVMlin_test_acc, SVMlin_test_prec, SVMlin_test_rec, SVMlin_test_time = me.test(SVMlin, y_test, X_test)\n",
    "print('Time: ' + str(SVMlin_train_time))\n",
    "me.print_scores(dp, SVMlin_test_acc, SVMlin_test_prec, SVMlin_test_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.5032401084899902\n",
      "Accuracy: 0.758538522637\n",
      "email \n",
      " F1:  0.980, P:  0.973, R:  0.987, \n",
      "internal_memo \n",
      " F1:  0.512, P:  0.508, R:  0.517, \n",
      "boardroom_minutes \n",
      " F1:  0.630, P:  0.548, R:  0.742, \n",
      "annual_report \n",
      " F1:  0.762, P:  0.800, R:  0.727, \n",
      "public_relations \n",
      " F1:  0.200, P:  0.250, R:  0.167, \n",
      "general_correspondance \n",
      " F1:  0.436, P:  0.398, R:  0.482, \n",
      "newspaper_article \n",
      " F1:  0.693, P:  0.703, R:  0.683, \n",
      "deposition \n",
      " F1:  0.621, P:  0.833, R:  0.495, \n",
      "scientific_article_unpublished \n",
      " F1:  0.754, P:  0.735, R:  0.773, \n",
      "scientific_article_published \n",
      " F1:  0.528, P:  0.677, R:  0.433, \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC, class-weighted\n",
    "SVMlincw = LinearSVC(class_weight='balanced')\n",
    "SVMlincw_train_acc, SVMlincw_train_time = me.train(SVMlincw, y_train, X_train)\n",
    "SVMlincw_test_acc, SVMlincw_test_prec, SVMlincw_test_rec, SVMlincw_test_time = me.test(SVMlincw, y_test, X_test)\n",
    "print('Time: ' + str(SVMlincw_train_time))\n",
    "me.print_scores(dp, SVMlincw_test_acc, SVMlincw_test_prec, SVMlincw_test_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15693 663\n"
     ]
    }
   ],
   "source": [
    "lp = LabelPropagator()\n",
    "hp_dists = SVMlin.decision_function(X_unlab)\n",
    "conf_scores = lp.confidence_scores(hp_dists)\n",
    "\n",
    "y_pred = SVMlin.predict(X_unlab).reshape(-1,1)\n",
    "y_est = lp.propagate_labels(y_pred, conf_scores, conf_threshold=1.5)\n",
    "\n",
    "print(y_est.shape[0], np.sum(y_est != -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
